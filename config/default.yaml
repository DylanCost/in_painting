# Model configuration
model:
  name: "unet_vae"
  input_channels: 3
  latent_dim: 512
  hidden_dims: [64, 128, 256, 512, 512]
  use_attention: true
  use_skip_connections: true
  dropout: 0.1

# Training configuration
training:
  batch_size: 32
  learning_rate: 0.0002
  beta1: 0.5
  beta2: 0.999
  epochs: 100
  gradient_clip: 1.0
  kl_weight: 0.001
  perceptual_weight: 0.1
  adversarial_weight: 0.001
  
# Data configuration
data:
  dataset: "celeba"
  data_path: "./data/celeba"
  image_size: 256
  num_workers: 4
  augmentation: true
  
# Mask configuration
mask:
  type: "random"  # random, center, irregular
  mask_ratio: 0.4
  min_size: 32
  max_size: 128
  
# Logging configuration
logging:
  use_wandb: true
  use_tensorboard: true
  log_interval: 100
  save_interval: 5
  sample_interval: 500
  checkpoint_dir: "./weights"
  log_dir: "./logs"